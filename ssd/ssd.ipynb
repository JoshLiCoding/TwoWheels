{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df179c11-fa57-4c10-89a7-93bcfb71d992",
   "metadata": {},
   "source": [
    "# SSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae698e8-d3f1-494b-814a-09ff87f44a38",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8fc6c4-b0ba-4fc2-9d35-73c191e83169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models.detection.ssd import SSDClassificationHead\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d12e49ff-d816-4b49-b8de-557a70b4b3ca",
   "metadata": {},
   "source": [
    "## Pre-Training\n",
    "\n",
    "Load SSD model with pretrained VGG16 backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a6f9e-bd91-4f50-8dc3-e7e6f27196d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssd = torchvision.models.detection.ssd300_vgg16(weights=models.detection.SSD300_VGG16_Weights.DEFAULT)\n",
    "ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa5383-89d5-4488-9306-7cc0365b7561",
   "metadata": {},
   "source": [
    "Change the final classification layer to predict the # of categories we are looking for (with same input dims and anchors nums). No need to alter the bounding box regression head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da613a7c-8ee0-4f80-84ff-652c612f89ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDFeatureExtractorVGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3-4): 2 x Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd.head.classification_head = SSDClassificationHead([512, 1024, 512, 256, 256, 256], [4, 6, 6, 6, 4, 4], 4)\n",
    "ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea9db0-2ff3-42b9-9cf4-e6103bceeb1f",
   "metadata": {},
   "source": [
    "Load 500 images from the dataset. Looks like the most common box category is cyclists, followed by pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca1cb8f-c0e8-4e72-8f11-e03f85d55a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "num = 500\n",
    "images = []\n",
    "targets = []\n",
    "\n",
    "labels_list = ['__background__','pedestrian', 'cyclist', 'motorcyclist', 'tricyclist', 'wheelchairuser', 'mopedrider']\n",
    "cyclist_cnt, ped_cnt, other_cnt = 0, 0, 0\n",
    "\n",
    "directory = list(os.walk('../dataset/labels'))\n",
    "for f in directory[0][2]:\n",
    "    if i >= num:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "    with open('../dataset/labels/' + f) as file:\n",
    "        jsonfile = json.load(file)\n",
    "\n",
    "        image = cv2.imread('../dataset/images/' +jsonfile['imagename'])\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        images.append(transform(image))\n",
    "\n",
    "        dict = {}\n",
    "        boxes, labels = [], []\n",
    "        for bbox in jsonfile['children']:\n",
    "            if bbox['identity'] == 'cyclist':\n",
    "                cyclist_cnt += 1\n",
    "            elif bbox['identity'] == 'pedestrian':\n",
    "                ped_cnt += 1\n",
    "            else:\n",
    "                other_cnt += 1\n",
    "            label = labels_list.index(bbox['identity'])\n",
    "            if label >= 3:\n",
    "                label = 3\n",
    "            labels.append(label)\n",
    "            boxes.append([bbox['mincol'], bbox['minrow'], bbox['maxcol'], bbox['maxrow']])\n",
    "        targets.append({'boxes': torch.tensor(boxes), 'labels': torch.tensor(labels)})\n",
    "print('cyclists: {}, pedestrians: {}, other: {}'.format(cyclist_cnt, ped_cnt, other_cnt))\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76140ef9-3c0b-43c2-b8f8-98698c44ad78",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552e13b-e266-4273-a405-c4e8e4ca694a",
   "metadata": {},
   "source": [
    "Fine tune our pretrained model on 300 images (with batch size of 20) for 10 epochs. Also save model parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2db858-0c05-48d4-b348-68e4e8a83db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(ssd.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34075164-1ef4-46ac-afb8-5753e7be3ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bbox_regression': tensor(1.7546, grad_fn=<DivBackward0>), 'classification': tensor(16.3597, grad_fn=<DivBackward0>)}\n",
      "1.7546128034591675 16.359731674194336\n",
      "{'bbox_regression': tensor(2.5137, grad_fn=<DivBackward0>), 'classification': tensor(13.9315, grad_fn=<DivBackward0>)}\n",
      "2.5137417316436768 13.93146800994873\n",
      "{'bbox_regression': tensor(2.4259, grad_fn=<DivBackward0>), 'classification': tensor(12.0371, grad_fn=<DivBackward0>)}\n",
      "2.4258642196655273 12.03707218170166\n",
      "{'bbox_regression': tensor(1.3071, grad_fn=<DivBackward0>), 'classification': tensor(10.6331, grad_fn=<DivBackward0>)}\n",
      "1.3070921897888184 10.633125305175781\n",
      "{'bbox_regression': tensor(5.1313, grad_fn=<DivBackward0>), 'classification': tensor(9.6497, grad_fn=<DivBackward0>)}\n",
      "5.131282806396484 9.649702072143555\n",
      "{'bbox_regression': tensor(3.3409, grad_fn=<DivBackward0>), 'classification': tensor(8.6232, grad_fn=<DivBackward0>)}\n",
      "3.3408775329589844 8.623205184936523\n",
      "{'bbox_regression': tensor(2.8852, grad_fn=<DivBackward0>), 'classification': tensor(7.8141, grad_fn=<DivBackward0>)}\n",
      "2.8851747512817383 7.814074993133545\n",
      "{'bbox_regression': tensor(2.1569, grad_fn=<DivBackward0>), 'classification': tensor(7.2394, grad_fn=<DivBackward0>)}\n",
      "2.156893253326416 7.239429950714111\n",
      "{'bbox_regression': tensor(0.8372, grad_fn=<DivBackward0>), 'classification': tensor(8.4333, grad_fn=<DivBackward0>)}\n",
      "0.8372446894645691 8.433323860168457\n",
      "{'bbox_regression': tensor(3.2430, grad_fn=<DivBackward0>), 'classification': tensor(7.0977, grad_fn=<DivBackward0>)}\n",
      "3.2429862022399902 7.097716808319092\n",
      "{'bbox_regression': tensor(2.4332, grad_fn=<DivBackward0>), 'classification': tensor(6.7659, grad_fn=<DivBackward0>)}\n",
      "2.433196544647217 6.76585578918457\n",
      "{'bbox_regression': tensor(1.8435, grad_fn=<DivBackward0>), 'classification': tensor(6.8225, grad_fn=<DivBackward0>)}\n",
      "1.8434780836105347 6.822460651397705\n",
      "{'bbox_regression': tensor(3.4586, grad_fn=<DivBackward0>), 'classification': tensor(6.7344, grad_fn=<DivBackward0>)}\n",
      "3.4585931301116943 6.734435081481934\n",
      "{'bbox_regression': tensor(2.9127, grad_fn=<DivBackward0>), 'classification': tensor(6.4653, grad_fn=<DivBackward0>)}\n",
      "2.91271710395813 6.465272903442383\n",
      "current model saved\n",
      "epoch 0 combined loss: 11.775044918060303\n",
      "{'bbox_regression': tensor(1.9348, grad_fn=<DivBackward0>), 'classification': tensor(6.5232, grad_fn=<DivBackward0>)}\n",
      "1.9347646236419678 6.523247718811035\n",
      "{'bbox_regression': tensor(2.8340, grad_fn=<DivBackward0>), 'classification': tensor(6.5358, grad_fn=<DivBackward0>)}\n",
      "2.8340041637420654 6.535790920257568\n",
      "{'bbox_regression': tensor(2.8628, grad_fn=<DivBackward0>), 'classification': tensor(6.4731, grad_fn=<DivBackward0>)}\n",
      "2.862849712371826 6.473111629486084\n",
      "{'bbox_regression': tensor(2.4333, grad_fn=<DivBackward0>), 'classification': tensor(6.5213, grad_fn=<DivBackward0>)}\n",
      "2.433337926864624 6.521335124969482\n",
      "{'bbox_regression': tensor(3.7628, grad_fn=<DivBackward0>), 'classification': tensor(6.5729, grad_fn=<DivBackward0>)}\n",
      "3.762770414352417 6.572885990142822\n",
      "{'bbox_regression': tensor(1.3292, grad_fn=<DivBackward0>), 'classification': tensor(6.6021, grad_fn=<DivBackward0>)}\n",
      "1.3291730880737305 6.602119445800781\n",
      "{'bbox_regression': tensor(1.9435, grad_fn=<DivBackward0>), 'classification': tensor(6.2732, grad_fn=<DivBackward0>)}\n",
      "1.943474292755127 6.273230075836182\n",
      "{'bbox_regression': tensor(2.1288, grad_fn=<DivBackward0>), 'classification': tensor(6.1411, grad_fn=<DivBackward0>)}\n",
      "2.1288275718688965 6.1411452293396\n",
      "{'bbox_regression': tensor(0.6228, grad_fn=<DivBackward0>), 'classification': tensor(6.1634, grad_fn=<DivBackward0>)}\n",
      "0.6227671504020691 6.163368225097656\n",
      "{'bbox_regression': tensor(5.9409, grad_fn=<DivBackward0>), 'classification': tensor(6.2081, grad_fn=<DivBackward0>)}\n",
      "5.9408650398254395 6.208063125610352\n",
      "{'bbox_regression': tensor(3.5042, grad_fn=<DivBackward0>), 'classification': tensor(6.0569, grad_fn=<DivBackward0>)}\n",
      "3.504237413406372 6.056928634643555\n",
      "{'bbox_regression': tensor(2.3527, grad_fn=<DivBackward0>), 'classification': tensor(5.9801, grad_fn=<DivBackward0>)}\n",
      "2.352691411972046 5.980069160461426\n",
      "{'bbox_regression': tensor(2.3075, grad_fn=<DivBackward0>), 'classification': tensor(6.0954, grad_fn=<DivBackward0>)}\n",
      "2.3074724674224854 6.095449924468994\n",
      "{'bbox_regression': tensor(2.0336, grad_fn=<DivBackward0>), 'classification': tensor(5.9290, grad_fn=<DivBackward0>)}\n",
      "2.0336029529571533 5.92903995513916\n",
      "current model saved\n",
      "epoch 1 combined loss: 8.861901589802333\n",
      "{'bbox_regression': tensor(1.9351, grad_fn=<DivBackward0>), 'classification': tensor(6.2021, grad_fn=<DivBackward0>)}\n",
      "1.9350666999816895 6.202148914337158\n",
      "{'bbox_regression': tensor(2.8766, grad_fn=<DivBackward0>), 'classification': tensor(6.0108, grad_fn=<DivBackward0>)}\n",
      "2.876560926437378 6.0107903480529785\n",
      "{'bbox_regression': tensor(2.4837, grad_fn=<DivBackward0>), 'classification': tensor(5.9460, grad_fn=<DivBackward0>)}\n",
      "2.4837450981140137 5.946044921875\n",
      "{'bbox_regression': tensor(0.7803, grad_fn=<DivBackward0>), 'classification': tensor(5.4772, grad_fn=<DivBackward0>)}\n",
      "0.7802984714508057 5.477199554443359\n",
      "{'bbox_regression': tensor(3.3051, grad_fn=<DivBackward0>), 'classification': tensor(6.1342, grad_fn=<DivBackward0>)}\n",
      "3.305119752883911 6.134207725524902\n",
      "{'bbox_regression': tensor(1.5817, grad_fn=<DivBackward0>), 'classification': tensor(6.1120, grad_fn=<DivBackward0>)}\n",
      "1.581740140914917 6.111950874328613\n",
      "{'bbox_regression': tensor(1.4734, grad_fn=<DivBackward0>), 'classification': tensor(5.7976, grad_fn=<DivBackward0>)}\n",
      "1.4733777046203613 5.7976460456848145\n",
      "{'bbox_regression': tensor(1.8142, grad_fn=<DivBackward0>), 'classification': tensor(5.6350, grad_fn=<DivBackward0>)}\n",
      "1.8141517639160156 5.634995460510254\n",
      "{'bbox_regression': tensor(0.4208, grad_fn=<DivBackward0>), 'classification': tensor(5.6218, grad_fn=<DivBackward0>)}\n",
      "0.4208032190799713 5.621798038482666\n",
      "{'bbox_regression': tensor(3.6084, grad_fn=<DivBackward0>), 'classification': tensor(5.8694, grad_fn=<DivBackward0>)}\n",
      "3.6083598136901855 5.869364261627197\n",
      "{'bbox_regression': tensor(2.4700, grad_fn=<DivBackward0>), 'classification': tensor(5.7549, grad_fn=<DivBackward0>)}\n",
      "2.469966411590576 5.754914283752441\n",
      "{'bbox_regression': tensor(1.2200, grad_fn=<DivBackward0>), 'classification': tensor(5.4895, grad_fn=<DivBackward0>)}\n",
      "1.2200343608856201 5.489508628845215\n",
      "{'bbox_regression': tensor(2.4225, grad_fn=<DivBackward0>), 'classification': tensor(5.8085, grad_fn=<DivBackward0>)}\n",
      "2.422536849975586 5.808506488800049\n",
      "{'bbox_regression': tensor(2.1027, grad_fn=<DivBackward0>), 'classification': tensor(5.5424, grad_fn=<DivBackward0>)}\n",
      "2.1026763916015625 5.5423994064331055\n",
      "current model saved\n",
      "epoch 2 combined loss: 7.849707978112357\n",
      "{'bbox_regression': tensor(1.4617, grad_fn=<DivBackward0>), 'classification': tensor(5.9840, grad_fn=<DivBackward0>)}\n",
      "1.4617096185684204 5.983956813812256\n",
      "{'bbox_regression': tensor(2.0950, grad_fn=<DivBackward0>), 'classification': tensor(5.7288, grad_fn=<DivBackward0>)}\n",
      "2.0950019359588623 5.728804111480713\n",
      "{'bbox_regression': tensor(1.7638, grad_fn=<DivBackward0>), 'classification': tensor(5.5554, grad_fn=<DivBackward0>)}\n",
      "1.7638068199157715 5.555415630340576\n",
      "{'bbox_regression': tensor(0.2732, grad_fn=<DivBackward0>), 'classification': tensor(5.6980, grad_fn=<DivBackward0>)}\n",
      "0.27317050099372864 5.698026657104492\n",
      "{'bbox_regression': tensor(2.0291, grad_fn=<DivBackward0>), 'classification': tensor(5.7060, grad_fn=<DivBackward0>)}\n",
      "2.029076337814331 5.706021308898926\n",
      "{'bbox_regression': tensor(0.8331, grad_fn=<DivBackward0>), 'classification': tensor(5.6806, grad_fn=<DivBackward0>)}\n",
      "0.8330539464950562 5.680627346038818\n",
      "{'bbox_regression': tensor(1.5323, grad_fn=<DivBackward0>), 'classification': tensor(5.4920, grad_fn=<DivBackward0>)}\n",
      "1.5322637557983398 5.492032527923584\n",
      "{'bbox_regression': tensor(1.1980, grad_fn=<DivBackward0>), 'classification': tensor(5.2553, grad_fn=<DivBackward0>)}\n",
      "1.19795823097229 5.255281925201416\n",
      "{'bbox_regression': tensor(0.3284, grad_fn=<DivBackward0>), 'classification': tensor(5.2501, grad_fn=<DivBackward0>)}\n",
      "0.3284188508987427 5.250137805938721\n",
      "{'bbox_regression': tensor(2.9475, grad_fn=<DivBackward0>), 'classification': tensor(5.5807, grad_fn=<DivBackward0>)}\n",
      "2.947510004043579 5.580650806427002\n",
      "{'bbox_regression': tensor(2.5195, grad_fn=<DivBackward0>), 'classification': tensor(5.4561, grad_fn=<DivBackward0>)}\n",
      "2.5195493698120117 5.456131458282471\n",
      "{'bbox_regression': tensor(1.8098, grad_fn=<DivBackward0>), 'classification': tensor(5.3016, grad_fn=<DivBackward0>)}\n",
      "1.809842586517334 5.301646709442139\n",
      "{'bbox_regression': tensor(2.1173, grad_fn=<DivBackward0>), 'classification': tensor(5.5035, grad_fn=<DivBackward0>)}\n",
      "2.117260217666626 5.503534317016602\n",
      "{'bbox_regression': tensor(2.0030, grad_fn=<DivBackward0>), 'classification': tensor(5.2649, grad_fn=<DivBackward0>)}\n",
      "2.00301194190979 5.264929294586182\n",
      "current model saved\n",
      "epoch 3 combined loss: 7.16920222554888\n",
      "{'bbox_regression': tensor(1.5186, grad_fn=<DivBackward0>), 'classification': tensor(5.6974, grad_fn=<DivBackward0>)}\n",
      "1.5186169147491455 5.697386264801025\n",
      "{'bbox_regression': tensor(1.5557, grad_fn=<DivBackward0>), 'classification': tensor(5.5085, grad_fn=<DivBackward0>)}\n",
      "1.5557236671447754 5.508516788482666\n",
      "{'bbox_regression': tensor(1.6646, grad_fn=<DivBackward0>), 'classification': tensor(5.3999, grad_fn=<DivBackward0>)}\n",
      "1.6646320819854736 5.3999342918396\n",
      "{'bbox_regression': tensor(0.9879, grad_fn=<DivBackward0>), 'classification': tensor(5.0507, grad_fn=<DivBackward0>)}\n",
      "0.9878865480422974 5.050682544708252\n",
      "{'bbox_regression': tensor(1.5702, grad_fn=<DivBackward0>), 'classification': tensor(5.3576, grad_fn=<DivBackward0>)}\n",
      "1.5702039003372192 5.357631683349609\n",
      "{'bbox_regression': tensor(0.6286, grad_fn=<DivBackward0>), 'classification': tensor(5.2989, grad_fn=<DivBackward0>)}\n",
      "0.628577470779419 5.298911094665527\n",
      "{'bbox_regression': tensor(1.3071, grad_fn=<DivBackward0>), 'classification': tensor(5.1726, grad_fn=<DivBackward0>)}\n",
      "1.3071092367172241 5.172606468200684\n",
      "{'bbox_regression': tensor(1.1269, grad_fn=<DivBackward0>), 'classification': tensor(4.9123, grad_fn=<DivBackward0>)}\n",
      "1.1268662214279175 4.912271976470947\n",
      "{'bbox_regression': tensor(0.3650, grad_fn=<DivBackward0>), 'classification': tensor(4.8838, grad_fn=<DivBackward0>)}\n",
      "0.3650062084197998 4.88375997543335\n",
      "{'bbox_regression': tensor(2.6722, grad_fn=<DivBackward0>), 'classification': tensor(5.3109, grad_fn=<DivBackward0>)}\n",
      "2.672153949737549 5.3109049797058105\n",
      "{'bbox_regression': tensor(2.3194, grad_fn=<DivBackward0>), 'classification': tensor(5.1819, grad_fn=<DivBackward0>)}\n",
      "2.3194468021392822 5.181872367858887\n",
      "{'bbox_regression': tensor(0.8184, grad_fn=<DivBackward0>), 'classification': tensor(4.9147, grad_fn=<DivBackward0>)}\n",
      "0.8184141516685486 4.914702892303467\n",
      "{'bbox_regression': tensor(2.1573, grad_fn=<DivBackward0>), 'classification': tensor(5.2180, grad_fn=<DivBackward0>)}\n",
      "2.157271385192871 5.2180256843566895\n",
      "{'bbox_regression': tensor(1.7771, grad_fn=<DivBackward0>), 'classification': tensor(5.1334, grad_fn=<DivBackward0>)}\n",
      "1.7770910263061523 5.133370876312256\n",
      "current model saved\n",
      "epoch 4 combined loss: 6.679255519594465\n",
      "{'bbox_regression': tensor(1.2967, grad_fn=<DivBackward0>), 'classification': tensor(5.5050, grad_fn=<DivBackward0>)}\n",
      "1.2966549396514893 5.504970073699951\n",
      "{'bbox_regression': tensor(1.5358, grad_fn=<DivBackward0>), 'classification': tensor(5.3006, grad_fn=<DivBackward0>)}\n",
      "1.535831093788147 5.3006181716918945\n",
      "{'bbox_regression': tensor(1.3889, grad_fn=<DivBackward0>), 'classification': tensor(5.0898, grad_fn=<DivBackward0>)}\n",
      "1.3888882398605347 5.089754581451416\n",
      "{'bbox_regression': tensor(0.2436, grad_fn=<DivBackward0>), 'classification': tensor(4.4777, grad_fn=<DivBackward0>)}\n",
      "0.2435905933380127 4.477731227874756\n",
      "{'bbox_regression': tensor(1.0898, grad_fn=<DivBackward0>), 'classification': tensor(5.1077, grad_fn=<DivBackward0>)}\n",
      "1.0897797346115112 5.107731342315674\n",
      "{'bbox_regression': tensor(1.2480, grad_fn=<DivBackward0>), 'classification': tensor(5.0541, grad_fn=<DivBackward0>)}\n",
      "1.248019814491272 5.054140567779541\n",
      "{'bbox_regression': tensor(0.7146, grad_fn=<DivBackward0>), 'classification': tensor(4.9685, grad_fn=<DivBackward0>)}\n",
      "0.7146130204200745 4.968538761138916\n",
      "{'bbox_regression': tensor(0.8044, grad_fn=<DivBackward0>), 'classification': tensor(4.7466, grad_fn=<DivBackward0>)}\n",
      "0.8044492602348328 4.746550559997559\n",
      "{'bbox_regression': tensor(0.2058, grad_fn=<DivBackward0>), 'classification': tensor(4.4902, grad_fn=<DivBackward0>)}\n",
      "0.2058379203081131 4.4901652336120605\n",
      "{'bbox_regression': tensor(2.4661, grad_fn=<DivBackward0>), 'classification': tensor(5.0993, grad_fn=<DivBackward0>)}\n",
      "2.466125965118408 5.099307537078857\n",
      "{'bbox_regression': tensor(2.2096, grad_fn=<DivBackward0>), 'classification': tensor(4.9741, grad_fn=<DivBackward0>)}\n",
      "2.2095584869384766 4.974052906036377\n",
      "{'bbox_regression': tensor(0.8607, grad_fn=<DivBackward0>), 'classification': tensor(4.7155, grad_fn=<DivBackward0>)}\n",
      "0.8607088327407837 4.715453147888184\n",
      "{'bbox_regression': tensor(1.8065, grad_fn=<DivBackward0>), 'classification': tensor(5.0343, grad_fn=<DivBackward0>)}\n",
      "1.806481122970581 5.034307956695557\n",
      "{'bbox_regression': tensor(1.6084, grad_fn=<DivBackward0>), 'classification': tensor(4.7931, grad_fn=<DivBackward0>)}\n",
      "1.6083528995513916 4.793121814727783\n",
      "current model saved\n",
      "epoch 5 combined loss: 6.202523980821882\n",
      "{'bbox_regression': tensor(1.1992, grad_fn=<DivBackward0>), 'classification': tensor(5.2726, grad_fn=<DivBackward0>)}\n",
      "1.1991758346557617 5.272629737854004\n",
      "{'bbox_regression': tensor(1.5337, grad_fn=<DivBackward0>), 'classification': tensor(5.1607, grad_fn=<DivBackward0>)}\n",
      "1.5337224006652832 5.160726547241211\n",
      "{'bbox_regression': tensor(1.2820, grad_fn=<DivBackward0>), 'classification': tensor(4.9143, grad_fn=<DivBackward0>)}\n",
      "1.281966209411621 4.91434383392334\n",
      "{'bbox_regression': tensor(0.1632, grad_fn=<DivBackward0>), 'classification': tensor(4.2741, grad_fn=<DivBackward0>)}\n",
      "0.16320984065532684 4.274089813232422\n",
      "{'bbox_regression': tensor(1.2825, grad_fn=<DivBackward0>), 'classification': tensor(4.8171, grad_fn=<DivBackward0>)}\n",
      "1.2824805974960327 4.817060947418213\n",
      "{'bbox_regression': tensor(0.4875, grad_fn=<DivBackward0>), 'classification': tensor(4.7952, grad_fn=<DivBackward0>)}\n",
      "0.48745113611221313 4.795174598693848\n",
      "{'bbox_regression': tensor(0.5307, grad_fn=<DivBackward0>), 'classification': tensor(4.7675, grad_fn=<DivBackward0>)}\n",
      "0.5306870937347412 4.7675089836120605\n",
      "{'bbox_regression': tensor(0.7089, grad_fn=<DivBackward0>), 'classification': tensor(4.5915, grad_fn=<DivBackward0>)}\n",
      "0.7088807225227356 4.591518402099609\n",
      "{'bbox_regression': tensor(0.1379, grad_fn=<DivBackward0>), 'classification': tensor(4.1837, grad_fn=<DivBackward0>)}\n",
      "0.13788621127605438 4.183708667755127\n",
      "{'bbox_regression': tensor(2.2898, grad_fn=<DivBackward0>), 'classification': tensor(4.9268, grad_fn=<DivBackward0>)}\n",
      "2.2898175716400146 4.926848888397217\n",
      "{'bbox_regression': tensor(2.1397, grad_fn=<DivBackward0>), 'classification': tensor(4.8254, grad_fn=<DivBackward0>)}\n",
      "2.1397244930267334 4.825397491455078\n",
      "{'bbox_regression': tensor(1.0828, grad_fn=<DivBackward0>), 'classification': tensor(4.6393, grad_fn=<DivBackward0>)}\n",
      "1.0828388929367065 4.639307022094727\n",
      "{'bbox_regression': tensor(1.7037, grad_fn=<DivBackward0>), 'classification': tensor(4.8695, grad_fn=<DivBackward0>)}\n",
      "1.703743815422058 4.869510650634766\n",
      "{'bbox_regression': tensor(1.6026, grad_fn=<DivBackward0>), 'classification': tensor(4.6395, grad_fn=<DivBackward0>)}\n",
      "1.6026309728622437 4.639484405517578\n",
      "current model saved\n",
      "epoch 6 combined loss: 5.9158232893262594\n",
      "{'bbox_regression': tensor(1.2287, grad_fn=<DivBackward0>), 'classification': tensor(5.2283, grad_fn=<DivBackward0>)}\n",
      "1.228692650794983 5.228252410888672\n",
      "{'bbox_regression': tensor(1.4114, grad_fn=<DivBackward0>), 'classification': tensor(5.0173, grad_fn=<DivBackward0>)}\n",
      "1.4113752841949463 5.017343997955322\n",
      "{'bbox_regression': tensor(1.2200, grad_fn=<DivBackward0>), 'classification': tensor(4.9064, grad_fn=<DivBackward0>)}\n",
      "1.2200137376785278 4.9063944816589355\n",
      "{'bbox_regression': tensor(0.0919, grad_fn=<DivBackward0>), 'classification': tensor(4.3628, grad_fn=<DivBackward0>)}\n",
      "0.09188464283943176 4.362844467163086\n",
      "{'bbox_regression': tensor(0.7985, grad_fn=<DivBackward0>), 'classification': tensor(4.5930, grad_fn=<DivBackward0>)}\n",
      "0.7985443472862244 4.592981815338135\n",
      "{'bbox_regression': tensor(0.2808, grad_fn=<DivBackward0>), 'classification': tensor(4.5720, grad_fn=<DivBackward0>)}\n",
      "0.28080326318740845 4.572005271911621\n",
      "{'bbox_regression': tensor(0.7919, grad_fn=<DivBackward0>), 'classification': tensor(4.5820, grad_fn=<DivBackward0>)}\n",
      "0.7919230461120605 4.5819926261901855\n",
      "{'bbox_regression': tensor(0.5520, grad_fn=<DivBackward0>), 'classification': tensor(4.3586, grad_fn=<DivBackward0>)}\n",
      "0.5520365834236145 4.3585686683654785\n",
      "{'bbox_regression': tensor(0.0895, grad_fn=<DivBackward0>), 'classification': tensor(3.9686, grad_fn=<DivBackward0>)}\n",
      "0.08946866542100906 3.9685888290405273\n",
      "{'bbox_regression': tensor(2.1527, grad_fn=<DivBackward0>), 'classification': tensor(4.7536, grad_fn=<DivBackward0>)}\n",
      "2.1526613235473633 4.753591537475586\n",
      "{'bbox_regression': tensor(2.0359, grad_fn=<DivBackward0>), 'classification': tensor(4.6483, grad_fn=<DivBackward0>)}\n",
      "2.03593111038208 4.6482625007629395\n",
      "{'bbox_regression': tensor(0.8139, grad_fn=<DivBackward0>), 'classification': tensor(4.3563, grad_fn=<DivBackward0>)}\n",
      "0.8139421343803406 4.356253623962402\n",
      "{'bbox_regression': tensor(1.5811, grad_fn=<DivBackward0>), 'classification': tensor(4.6773, grad_fn=<DivBackward0>)}\n",
      "1.5810843706130981 4.677315711975098\n",
      "{'bbox_regression': tensor(1.5320, grad_fn=<DivBackward0>), 'classification': tensor(4.4538, grad_fn=<DivBackward0>)}\n",
      "1.532023549079895 4.453845977783203\n",
      "current model saved\n",
      "epoch 7 combined loss: 5.647044726780483\n",
      "{'bbox_regression': tensor(1.1503, grad_fn=<DivBackward0>), 'classification': tensor(4.9882, grad_fn=<DivBackward0>)}\n",
      "1.150258183479309 4.988152980804443\n",
      "{'bbox_regression': tensor(1.3548, grad_fn=<DivBackward0>), 'classification': tensor(4.8788, grad_fn=<DivBackward0>)}\n",
      "1.3548489809036255 4.878765106201172\n",
      "{'bbox_regression': tensor(1.1509, grad_fn=<DivBackward0>), 'classification': tensor(4.6099, grad_fn=<DivBackward0>)}\n",
      "1.1509311199188232 4.609880447387695\n",
      "{'bbox_regression': tensor(0.1748, grad_fn=<DivBackward0>), 'classification': tensor(3.7903, grad_fn=<DivBackward0>)}\n",
      "0.17481352388858795 3.7902626991271973\n",
      "{'bbox_regression': tensor(0.4170, grad_fn=<DivBackward0>), 'classification': tensor(4.4071, grad_fn=<DivBackward0>)}\n",
      "0.41701340675354004 4.407105922698975\n",
      "{'bbox_regression': tensor(0.4941, grad_fn=<DivBackward0>), 'classification': tensor(4.3945, grad_fn=<DivBackward0>)}\n",
      "0.4941099286079407 4.394540309906006\n",
      "{'bbox_regression': tensor(0.5485, grad_fn=<DivBackward0>), 'classification': tensor(4.4464, grad_fn=<DivBackward0>)}\n",
      "0.5485167503356934 4.4463582038879395\n",
      "{'bbox_regression': tensor(0.5552, grad_fn=<DivBackward0>), 'classification': tensor(4.2834, grad_fn=<DivBackward0>)}\n",
      "0.5551637411117554 4.283379554748535\n",
      "{'bbox_regression': tensor(0.1013, grad_fn=<DivBackward0>), 'classification': tensor(3.6815, grad_fn=<DivBackward0>)}\n",
      "0.10125360637903214 3.6815202236175537\n",
      "{'bbox_regression': tensor(1.9962, grad_fn=<DivBackward0>), 'classification': tensor(4.6202, grad_fn=<DivBackward0>)}\n",
      "1.9962081909179688 4.620233535766602\n",
      "{'bbox_regression': tensor(1.9508, grad_fn=<DivBackward0>), 'classification': tensor(4.5239, grad_fn=<DivBackward0>)}\n",
      "1.9508026838302612 4.5238871574401855\n",
      "{'bbox_regression': tensor(0.7400, grad_fn=<DivBackward0>), 'classification': tensor(4.2640, grad_fn=<DivBackward0>)}\n",
      "0.7399705648422241 4.264042854309082\n",
      "{'bbox_regression': tensor(1.1674, grad_fn=<DivBackward0>), 'classification': tensor(4.5272, grad_fn=<DivBackward0>)}\n",
      "1.1674281358718872 4.527189254760742\n",
      "{'bbox_regression': tensor(1.3987, grad_fn=<DivBackward0>), 'classification': tensor(4.3276, grad_fn=<DivBackward0>)}\n",
      "1.3987313508987427 4.327632427215576\n",
      "current model saved\n",
      "epoch 8 combined loss: 5.353071519306728\n",
      "{'bbox_regression': tensor(1.0862, grad_fn=<DivBackward0>), 'classification': tensor(4.8567, grad_fn=<DivBackward0>)}\n",
      "1.086197018623352 4.856723785400391\n",
      "{'bbox_regression': tensor(1.2736, grad_fn=<DivBackward0>), 'classification': tensor(4.7595, grad_fn=<DivBackward0>)}\n",
      "1.2735968828201294 4.759463310241699\n",
      "{'bbox_regression': tensor(0.9844, grad_fn=<DivBackward0>), 'classification': tensor(4.5198, grad_fn=<DivBackward0>)}\n",
      "0.9843528866767883 4.5197978019714355\n",
      "{'bbox_regression': tensor(0.0647, grad_fn=<DivBackward0>), 'classification': tensor(3.5047, grad_fn=<DivBackward0>)}\n",
      "0.0646517425775528 3.504650115966797\n",
      "{'bbox_regression': tensor(0.6448, grad_fn=<DivBackward0>), 'classification': tensor(4.2225, grad_fn=<DivBackward0>)}\n",
      "0.6448279619216919 4.222468852996826\n",
      "{'bbox_regression': tensor(0.2699, grad_fn=<DivBackward0>), 'classification': tensor(4.2111, grad_fn=<DivBackward0>)}\n",
      "0.2699090838432312 4.211139678955078\n",
      "{'bbox_regression': tensor(0.3221, grad_fn=<DivBackward0>), 'classification': tensor(4.2710, grad_fn=<DivBackward0>)}\n",
      "0.32208046317100525 4.271048545837402\n",
      "{'bbox_regression': tensor(0.4751, grad_fn=<DivBackward0>), 'classification': tensor(4.0697, grad_fn=<DivBackward0>)}\n",
      "0.47513651847839355 4.069737434387207\n",
      "{'bbox_regression': tensor(0.0517, grad_fn=<DivBackward0>), 'classification': tensor(3.5118, grad_fn=<DivBackward0>)}\n",
      "0.05165547505021095 3.5117900371551514\n",
      "{'bbox_regression': tensor(1.9190, grad_fn=<DivBackward0>), 'classification': tensor(4.4828, grad_fn=<DivBackward0>)}\n",
      "1.9189982414245605 4.482829570770264\n",
      "{'bbox_regression': tensor(1.8527, grad_fn=<DivBackward0>), 'classification': tensor(4.3676, grad_fn=<DivBackward0>)}\n",
      "1.8527257442474365 4.3675923347473145\n",
      "{'bbox_regression': tensor(0.6958, grad_fn=<DivBackward0>), 'classification': tensor(4.1212, grad_fn=<DivBackward0>)}\n",
      "0.6958102583885193 4.121158123016357\n",
      "{'bbox_regression': tensor(1.0508, grad_fn=<DivBackward0>), 'classification': tensor(4.3889, grad_fn=<DivBackward0>)}\n",
      "1.0508185625076294 4.388862133026123\n",
      "{'bbox_regression': tensor(1.3468, grad_fn=<DivBackward0>), 'classification': tensor(4.1697, grad_fn=<DivBackward0>)}\n",
      "1.3468022346496582 4.169732570648193\n",
      "current model saved\n",
      "epoch 9 combined loss: 5.106754081589835\n",
      "time 3347.346176624298\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "best_loss = 1000\n",
    "file = os.path.join(os.getcwd(), 'ssd.pt')\n",
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    ssd.train()\n",
    "    loss_sublist = []\n",
    "    for i in range(15):\n",
    "        # print(i)\n",
    "        cur = i*20\n",
    "        X = images[cur:cur+20]\n",
    "        y = targets[cur:cur+20]\n",
    "        \n",
    "        j = 0\n",
    "        while j < len(y):\n",
    "            if len(y[j]['boxes'].detach().numpy()) == 0:\n",
    "                X.pop(j)\n",
    "                y.pop(j)\n",
    "                j -= 1\n",
    "            j += 1\n",
    "        if len(y) == 0:\n",
    "            continue\n",
    "\n",
    "        loss = ssd(X, y)\n",
    "        print(loss)\n",
    "        losses = sum(l for l in loss.values())\n",
    "        print(str(loss['bbox_regression'].item()), str(loss['classification'].item()))\n",
    "        loss_sublist.append(losses.item())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    loss_list.append(np.mean(loss_sublist))\n",
    "    if np.mean(loss_sublist) < best_loss:\n",
    "        torch.save(ssd.state_dict(), file)\n",
    "        best_loss = np.mean(loss_sublist)\n",
    "        print('current model saved')\n",
    "    \n",
    "    print('epoch '+str(epoch)+' combined loss: '+str(loss_list[-1]))\n",
    "end = time.time()\n",
    "print('time', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02465e3d-79ee-4c49-b412-f6f5d3909384",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17669a-47e9-4fc1-a1d8-86322e80e6c2",
   "metadata": {},
   "source": [
    "Let's visualize how our model performs on the same dataset as Faster R-CNN. Note that all of these images were used during training (since we selected 300 images instead of 100), but we can still see that the results are poor. Here, I've tweaked the code below to save 30 images each to folders images1/, images2/ and images3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b19977c-9654-438f-9734-9c530a7a68af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_34752\\3802797056.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ssd.load_state_dict(torch.load('ssd.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd.load_state_dict(torch.load('ssd.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef81205-f485-4309-99f1-39f09d7597ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_labels_list = ['__background__','pedestrian', 'cyclist', 'other']\n",
    "\n",
    "ssd.eval()\n",
    "for i in range(30):\n",
    "    X = images[i] # 0, 135, 210\n",
    "    X_vis = (X.detach().numpy().transpose(1, 2, 0)*255).astype(np.int32).copy()\n",
    "    z = ssd([X])\n",
    "    boxes, labels, scores = z[0]['boxes'], z[0]['labels'], z[0]['scores']\n",
    "    print(scores)\n",
    "    for box, label, score in zip(boxes.detach().numpy(), labels.detach().numpy(), scores.detach().numpy()):\n",
    "        if score < 0.5: \n",
    "            continue\n",
    "        #print(box, label)\n",
    "        color = (255, 255, 255)\n",
    "        if labels_list[label] == 'cyclist':\n",
    "            color = (0, 255, 0)\n",
    "        elif labels_list[label] == 'pedestrian':\n",
    "            color = (0, 0, 255)\n",
    "        bbox = [int(pt) for pt in box]\n",
    "        cv2.rectangle(X_vis, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, thickness=2)\n",
    "        cv2.putText(X_vis, new_labels_list[label], (bbox[0], bbox[1]), color=color, fontFace=0, fontScale=1)\n",
    "    cv2.imwrite('images1/'+str(i)+'.png', X_vis)\n",
    "    # plt.imshow(X_vis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7399a9b-5529-4d79-b597-8f269c5f3e63",
   "metadata": {},
   "source": [
    "Let's also plot the training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a55a227d-af3b-4b8f-b747-42e32bf926bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(list(range(10)), loss_list)\n",
    "ax.set_ylabel('combined loss')\n",
    "ax.set_xlabel('epochs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a38b49-10b0-40a7-a63d-898b398352aa",
   "metadata": {},
   "source": [
    "We can calculate the mAP of our model. The code below prepares input to the mAP script, evaluating on out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "072e01f8-74d8-45ce-af69-7a1e12bad579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssd.eval()\n",
    "for i in range(30):\n",
    "    X = images[i+300]\n",
    "    y = targets[i+300]\n",
    "    X_vis = (X.detach().numpy().transpose(1, 2, 0)*255).astype(np.int32).copy()\n",
    "    #cv2.imwrite('images-optional/'+str(i)+'.png', X_vis)\n",
    "    \n",
    "    with open('ground-truth/'+str(i)+'.txt', 'w') as f:\n",
    "        boxes, labels = y['boxes'], y['labels']\n",
    "        for box, label in zip(boxes.detach().numpy(), labels):\n",
    "            f.write(new_labels_list[label]+' '+str(box[0])+' '+str(box[1])+' '+str(box[2])+' '+str(box[3])+'\\n')\n",
    "    \n",
    "    z = ssd([X])\n",
    "    boxes, labels, scores = z[0]['boxes'], z[0]['labels'], z[0]['scores']\n",
    "    with open('detection-results/'+str(i)+'.txt', 'w') as f:\n",
    "        for box, label, score in zip(boxes.detach().numpy(), labels.detach().numpy(), scores.detach().numpy()):\n",
    "            if score < 0.5: \n",
    "                continue\n",
    "            bbox = [int(pt) for pt in box]\n",
    "            f.write(new_labels_list[label]+' '+str(score)+' '+str(bbox[0])+' '+str(bbox[1])+' '+str(bbox[2])+' '+str(bbox[3])+'\\n')\n",
    "        bbox = [int(pt) for pt in box]\n",
    "        bbox = [int(pt) for pt in box]\n",
    "    #plt.imshow(X_vis)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
