{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c1587d-7add-42e1-8a80-1bd10e9ed95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import torch\n",
    "import gradio as gr\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ddd31f5-ef8f-48a7-8620-7ff3c4f840c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('../yolo/runs/detect/train22/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def350e3-f67e-439a-b07f-aae0bf16c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_pred(image):\n",
    "    result = model.predict(image)[0]\n",
    "    annotator = Annotator(result.orig_img)\n",
    "    color_list = [(107, 31, 45), (32, 102, 50), (32, 45, 102)]\n",
    "    for label in result.boxes.data.detach().numpy():\n",
    "        annotator.box_label(\n",
    "            label[0:4],\n",
    "            str(result.names[label[-1].item()]) + \" \" + str(round(label[-2], 2)),\n",
    "            color_list[int(label[-1].item())]\n",
    "        )\n",
    "        print(round(label[-2], 2))\n",
    "    return annotator.im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fe21501-4c75-43fb-bbec-e06cec4f3da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=yolo_pred, \n",
    "             inputs=\"image\", \n",
    "             outputs=\"image\",\n",
    "             examples=[\n",
    "                 [cv2.imread(\"example1.jpg\")],\n",
    "                 [cv2.imread(\"example2.jpg\")],\n",
    "                 [cv2.imread(\"example3.jpg\")],\n",
    "             ],\n",
    "             title=\"Fine-Tuned YOLOv8\",\n",
    "             description=\"\"\"YOLOv8 object detection model trained on the Tsinghua-Daimler Cyclist Benchmark (TDCB). \n",
    "                             Since the setting of their image collection seems to be an early morning in China,\n",
    "                             please sample similar images for the best results. I recommend using images from TDCB's\n",
    "                             Kaggle clone here: https://www.kaggle.com/datasets/semiemptyglass/cyclist-dataset.\"\"\"\n",
    "            ).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a5be1-905a-4b15-8877-bfc3795d9a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
